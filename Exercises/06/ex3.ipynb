{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 30\n",
    "PATH = '.cifar_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=32,\n",
    "            kernel_size=5,\n",
    "            padding='same',\n",
    "            stride=1,\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.max_pool = torch.nn.MaxPool2d(2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.dense = torch.nn.Linear(\n",
    "            in_features=8192,\n",
    "            out_features=10\n",
    "        )\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]           2,432\n",
      "              ReLU-2           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 32, 16, 16]               0\n",
      "           Flatten-4                 [-1, 8192]               0\n",
      "            Linear-5                   [-1, 10]          81,930\n",
      "           Softmax-6                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 84,362\n",
      "Trainable params: 84,362\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.63\n",
      "Params size (MB): 0.32\n",
      "Estimated Total Size (MB): 0.96\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29998/1797031239.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "torchsummary.summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29998/1797031239.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.015152500298023223, accuracy: 0.5254200100898743\n",
      "epoch: 1, loss: 0.014814255061149598, accuracy: 0.570360004901886\n",
      "epoch: 2, loss: 0.014584864485263825, accuracy: 0.6008800268173218\n",
      "epoch: 3, loss: 0.014407417750358581, accuracy: 0.6222400069236755\n",
      "epoch: 4, loss: 0.014242905604839325, accuracy: 0.6442199945449829\n",
      "epoch: 5, loss: 0.01412603346824646, accuracy: 0.6594799757003784\n",
      "epoch: 6, loss: 0.01400447177886963, accuracy: 0.6757400035858154\n",
      "epoch: 7, loss: 0.013902996079921723, accuracy: 0.6888200044631958\n",
      "epoch: 8, loss: 0.013837937383651733, accuracy: 0.6976600289344788\n",
      "epoch: 9, loss: 0.01375082513332367, accuracy: 0.7095400094985962\n",
      "epoch: 10, loss: 0.013692607021331788, accuracy: 0.716920018196106\n",
      "epoch: 11, loss: 0.013638248076438904, accuracy: 0.7240399718284607\n",
      "epoch: 12, loss: 0.013603702394962312, accuracy: 0.7283999919891357\n",
      "epoch: 13, loss: 0.013522961864471435, accuracy: 0.7392399907112122\n",
      "epoch: 14, loss: 0.013490196342468262, accuracy: 0.7439799904823303\n",
      "epoch: 15, loss: 0.01346399852514267, accuracy: 0.7465400099754333\n",
      "epoch: 16, loss: 0.013406165478229523, accuracy: 0.7541599869728088\n",
      "epoch: 17, loss: 0.013366493268013, accuracy: 0.7603600025177002\n",
      "epoch: 18, loss: 0.013330166952610016, accuracy: 0.7635599970817566\n",
      "epoch: 19, loss: 0.013298616647720337, accuracy: 0.7681000232696533\n",
      "epoch: 20, loss: 0.013270329840183259, accuracy: 0.7718600034713745\n",
      "epoch: 21, loss: 0.013225589578151703, accuracy: 0.7777600288391113\n",
      "epoch: 22, loss: 0.013189695374965667, accuracy: 0.7824599742889404\n",
      "epoch: 23, loss: 0.013167817451953888, accuracy: 0.7854800224304199\n",
      "epoch: 24, loss: 0.013151987020969392, accuracy: 0.7865800261497498\n",
      "epoch: 25, loss: 0.013124799509048463, accuracy: 0.7900599837303162\n",
      "epoch: 26, loss: 0.013097609131336212, accuracy: 0.7943400144577026\n",
      "epoch: 27, loss: 0.013062831916809082, accuracy: 0.7983800172805786\n",
      "epoch: 28, loss: 0.013043252274990081, accuracy: 0.8008599877357483\n",
      "epoch: 29, loss: 0.013023183562755584, accuracy: 0.8022599816322327\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    training_cost = 0.0\n",
    "    training_correct = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        cost = loss_func(predictions, targets)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        training_cost += cost.item()\n",
    "        training_correct += (torch.argmax(predictions, dim=1) == targets).sum()\n",
    "    training_cost /= len(train_set)\n",
    "    training_correct /= len(train_set)\n",
    "    print(f'epoch: {epoch}, loss: {training_cost}, accuracy: {training_correct}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29998/1797031239.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.657800018787384\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        predictions = model(inputs)\n",
    "        torch.argmax(predictions)\n",
    "        correct += (torch.argmax(predictions, dim=1) == targets).sum()\n",
    "\n",
    "print(f'Accuracy on training set: {correct / len(test_set)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a77e0c44eba510a7cc44ef7205295bb97273d712ef38e57931ce4147c03543f4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
