{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "N_EPOCHS = 30\n",
    "PATH = '.cifar_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=32,\n",
    "            kernel_size=5,\n",
    "            padding='same',\n",
    "            stride=1,\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.max_pool = torch.nn.MaxPool2d(2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.dense = torch.nn.Linear(\n",
    "            in_features=8192,\n",
    "            out_features=10\n",
    "        )\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]           2,432\n",
      "              ReLU-2           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 32, 16, 16]               0\n",
      "           Flatten-4                 [-1, 8192]               0\n",
      "            Linear-5                   [-1, 10]          81,930\n",
      "           Softmax-6                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 84,362\n",
      "Trainable params: 84,362\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.63\n",
      "Params size (MB): 0.32\n",
      "Estimated Total Size (MB): 0.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "torchsummary.summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.015904964723587035, accuracy: 0.4272800087928772\n",
      "epoch: 1, loss: 0.015096047685146332, accuracy: 0.5322999954223633\n",
      "epoch: 2, loss: 0.014794114100933075, accuracy: 0.5718200206756592\n",
      "epoch: 3, loss: 0.014603384749889373, accuracy: 0.5968199968338013\n",
      "epoch: 4, loss: 0.014413966915607453, accuracy: 0.621940016746521\n",
      "epoch: 5, loss: 0.014277198133468628, accuracy: 0.6399199962615967\n",
      "epoch: 6, loss: 0.014153855376243592, accuracy: 0.6564000248908997\n",
      "epoch: 7, loss: 0.014065924696922302, accuracy: 0.667959988117218\n",
      "epoch: 8, loss: 0.013979237813949585, accuracy: 0.6791800260543823\n",
      "epoch: 9, loss: 0.013890659244060516, accuracy: 0.6909400224685669\n",
      "epoch: 10, loss: 0.013830155682563782, accuracy: 0.6980599761009216\n",
      "epoch: 11, loss: 0.013767866780757905, accuracy: 0.7066199779510498\n",
      "epoch: 12, loss: 0.013704174511432647, accuracy: 0.7148799896240234\n",
      "epoch: 13, loss: 0.013653777306079865, accuracy: 0.722000002861023\n",
      "epoch: 14, loss: 0.013608135764598846, accuracy: 0.7275199890136719\n",
      "epoch: 15, loss: 0.013566062610149384, accuracy: 0.7329199910163879\n",
      "epoch: 16, loss: 0.0135125200176239, accuracy: 0.7397800087928772\n",
      "epoch: 17, loss: 0.013468637759685516, accuracy: 0.7460600137710571\n",
      "epoch: 18, loss: 0.013434001054763793, accuracy: 0.751039981842041\n",
      "epoch: 19, loss: 0.013398388724327087, accuracy: 0.7550600171089172\n",
      "epoch: 20, loss: 0.013356314661502838, accuracy: 0.7609400153160095\n",
      "epoch: 21, loss: 0.013322979989051818, accuracy: 0.764460027217865\n",
      "epoch: 22, loss: 0.01328990395784378, accuracy: 0.7694399952888489\n",
      "epoch: 23, loss: 0.013266824312210082, accuracy: 0.7718799710273743\n",
      "epoch: 24, loss: 0.013248477821350097, accuracy: 0.7741600275039673\n",
      "epoch: 25, loss: 0.013206549773216248, accuracy: 0.7790200114250183\n",
      "epoch: 26, loss: 0.01316868446111679, accuracy: 0.784280002117157\n",
      "epoch: 27, loss: 0.01315184092760086, accuracy: 0.7865200042724609\n",
      "epoch: 28, loss: 0.01313088418483734, accuracy: 0.789080023765564\n",
      "epoch: 29, loss: 0.013117492461204529, accuracy: 0.7905399799346924\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    training_cost = 0.0\n",
    "    training_correct = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        cost = loss_func(predictions, targets)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        training_cost += cost.item()\n",
    "        training_correct += (torch.argmax(predictions, dim=1) == targets).sum()\n",
    "    training_cost /= len(train_set)\n",
    "    training_correct /= len(train_set)\n",
    "    print(f'epoch: {epoch}, loss: {training_cost}, accuracy: {training_correct}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.659500002861023\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        predictions = model(inputs)\n",
    "        torch.argmax(predictions)\n",
    "        correct += (torch.argmax(predictions, dim=1) == targets).sum()\n",
    "\n",
    "print(f'Accuracy on training set: {correct / len(test_set)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a77e0c44eba510a7cc44ef7205295bb97273d712ef38e57931ce4147c03543f4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
